}
optimize(f,c(-10,10),tol=.Machine$double.eps^0.5)
g = function(a){
(a-2)^2*(a+2)^2
}
optimize(g,c(-10,0),tol=.Machine$double.eps^0.5)
optimize(g,c(0,10),tol=.Machine$double.eps^0.5)
optimize(g,c(-10,10),tol=.Machine$double.eps^0.5)
h = function(a,phi,theta){
(phi+theta/(1+theta)-a)^2
}
phi = 5
theta = -6
optimize(h,c(-100,100),phi=phi,theta=theta,tol=.Machine$double.eps^0.5)
opt_h_out = optimize(h,c(-100,100),phi=phi,theta=theta,tol=.Machine$double.eps^0.5)
print(opt_h_out)
print(opt_h_out$minimum)
print(opt_h_out$objective)
mean_squared_error_loss = function(a,y){
out = mean((y-a)^2)
return(out)
}
mean_absolute_error_loss = function(a,y){
out = mean(abs(y-a))
return(out)
}
data(rock)
y = rock$shape
plot(density(y,from=0),main="Density Estimate from Rock Sample")
lower = min(y)
upper = max(y)
interval = c(lower,upper)
a_hat_mean = optimize(mean_squared_error_loss,interval,y=y,tol=.Machine$double.eps^0.5)
print(c(est=a_hat_mean$minimum, mean=mean(y)))
a_hat_median = optimize(mean_absolute_error_loss,interval,y=y,tol=.Machine$double.eps^0.5)
print(c(est=a_hat_median$minimum, median=median(y)))
mean_huber_loss = function(a,y,caliper){
# first, a check to make sure the caliper is >0
if(caliper==0){caliper=1}else if(caliper<0){caliper= -caliper}
# we use ifelse to do logical comparisons on a vector
huber_loss = ifelse(abs(y-a)<=caliper,(y-a)^2/2,caliper*abs(y-a)-caliper^2/2)
out = mean(huber_loss)
return(out)
}
caliper = 0.1
a_hat_huber = optimize(mean_huber_loss,interval,y=y,caliper=caliper,tol=.Machine$double.eps^0.5)
a_hat_huber$minimum
caliper = 0.2
a_hat_huber = optimize(mean_huber_loss,interval,y=y,caliper=caliper,tol=.Machine$double.eps^0.5)
a_hat_huber$minimum
caliper = 0.05
a_hat_huber = optimize(mean_huber_loss,interval,y=y,caliper=caliper,tol=.Machine$double.eps^0.5)
a_hat_huber$minimum
M = 10000
caliper = seq(0.001,max(y)-min(y),length.out=M)
a_hat_huber = rep(NA,M)
for(i in 1:M){
a_hat_huber[i] = optimize(mean_huber_loss,interval,y=y,caliper=caliper[i],tol=.Machine$double.eps^0.5)$minimum
}
plot(a_hat_huber~caliper,type="l",xlab="Caliper",ylab="Estimate",main="Estimates from Huber Risk")
hyperbolic_loss = function(a,y,delta){
return(mean(sqrt(delta^2 + (y-a)^2) - delta))
# We take the mean because y is a vector and computing the value requires the average of the hyperbolic loss for the entire vector y
}
y <- rock$shape
delta <- 0.5
# the arguments a and delta are scalar while y is a vector
optimize(hyperbolic_loss, interval=range(y), y=y, delta=delta, tol=.Machine$double.eps^0.5)
hyperbolic_from_risk_minimization = function(x, ind=c(1:length(x)), delta) {
x = x[ind]
g = function(theta) {
return(mean(hyperbolic_loss(theta,x,delta)))
}
optimize_out = optimize(f=g,interval=range(x))
return(optimize_out$minimum)
}
V_hyperbolic_from_risk_minimization = Vectorize(hyperbolic_from_risk_minimization, vectorize.args = "delta")
delta = seq(0.001,max(y)-min(y),length.out=10000)
caliper = delta
hyperbolic_estimates = V_hyperbolic_from_risk_minimization(x=y,delta=delta)
plot(hyperbolic_estimates~delta, xlim=c(0,0.3), ylim=c(0.194,0.22), xlab = "Estimate", ylab= "Delta/Caliper")
abline(v=a_hat_mean$minimum, col="blue")
abline(v=a_hat_median$minimum, col="green")
lines(a_hat_huber~delta, col="red")
legend(x="topleft", cex = 1, legend=c("Hyperbolic Estimates", "Huber Estimates", "Mean Estimate", "Median Estimate"), fill = c("black", "red", "blue", "green"))
library(boot)
data(bigcity)
y = bigcity$x
knitr::opts_chunk$set(echo = TRUE)
f = function(a){
a^2-2*a+1
}
optimize(f,c(-10,10),tol=.Machine$double.eps^0.5)
g = function(a){
(a-2)^2*(a+2)^2
}
optimize(g,c(-10,0),tol=.Machine$double.eps^0.5)
optimize(g,c(0,10),tol=.Machine$double.eps^0.5)
optimize(g,c(-10,10),tol=.Machine$double.eps^0.5)
h = function(a,phi,theta){
(phi+theta/(1+theta)-a)^2
}
phi = 5
theta = -6
optimize(h,c(-100,100),phi=phi,theta=theta,tol=.Machine$double.eps^0.5)
opt_h_out = optimize(h,c(-100,100),phi=phi,theta=theta,tol=.Machine$double.eps^0.5)
print(opt_h_out)
print(opt_h_out$minimum)
print(opt_h_out$objective)
mean_squared_error_loss = function(a,y){
out = mean((y-a)^2)
return(out)
}
mean_absolute_error_loss = function(a,y){
out = mean(abs(y-a))
return(out)
}
data(rock)
y = rock$shape
plot(density(y,from=0),main="Density Estimate from Rock Sample")
lower = min(y)
upper = max(y)
interval = c(lower,upper)
a_hat_mean = optimize(mean_squared_error_loss,interval,y=y,tol=.Machine$double.eps^0.5)
print(c(est=a_hat_mean$minimum, mean=mean(y)))
a_hat_median = optimize(mean_absolute_error_loss,interval,y=y,tol=.Machine$double.eps^0.5)
print(c(est=a_hat_median$minimum, median=median(y)))
mean_huber_loss = function(a,y,caliper){
# first, a check to make sure the caliper is >0
if(caliper==0){caliper=1}else if(caliper<0){caliper= -caliper}
# we use ifelse to do logical comparisons on a vector
huber_loss = ifelse(abs(y-a)<=caliper,(y-a)^2/2,caliper*abs(y-a)-caliper^2/2)
out = mean(huber_loss)
return(out)
}
caliper = 0.1
a_hat_huber = optimize(mean_huber_loss,interval,y=y,caliper=caliper,tol=.Machine$double.eps^0.5)
a_hat_huber$minimum
caliper = 0.2
a_hat_huber = optimize(mean_huber_loss,interval,y=y,caliper=caliper,tol=.Machine$double.eps^0.5)
a_hat_huber$minimum
caliper = 0.05
a_hat_huber = optimize(mean_huber_loss,interval,y=y,caliper=caliper,tol=.Machine$double.eps^0.5)
a_hat_huber$minimum
M = 10000
caliper = seq(0.001,max(y)-min(y),length.out=M)
a_hat_huber = rep(NA,M)
for(i in 1:M){
a_hat_huber[i] = optimize(mean_huber_loss,interval,y=y,caliper=caliper[i],tol=.Machine$double.eps^0.5)$minimum
}
plot(a_hat_huber~caliper,type="l",xlab="Caliper",ylab="Estimate",main="Estimates from Huber Risk")
hyperbolic_loss = function(a,y,delta){
return(mean(sqrt(delta^2 + (y-a)^2) - delta))
# We take the mean because y is a vector and computing the value requires the average of the hyperbolic loss for the entire vector y
}
y <- rock$shape
delta <- 0.5
# the arguments a and delta are scalar while y is a vector
optimize(hyperbolic_loss, interval=range(y), y=y, delta=delta, tol=.Machine$double.eps^0.5)
hyperbolic_from_risk_minimization = function(x, ind=c(1:length(x)), delta) {
x = x[ind]
g = function(theta) {
return(mean(hyperbolic_loss(theta,x,delta)))
}
optimize_out = optimize(f=g,interval=range(x))
return(optimize_out$minimum)
}
V_hyperbolic_from_risk_minimization = Vectorize(hyperbolic_from_risk_minimization, vectorize.args = "delta")
delta = seq(0.001,max(y)-min(y),length.out=10000)
caliper = delta
hyperbolic_estimates = V_hyperbolic_from_risk_minimization(x=y,delta=delta)
plot(hyperbolic_estimates~delta, xlim=c(0,0.3), ylim=c(0.194,0.22), xlab = "Estimate", ylab= "Delta/Caliper")
abline(v=a_hat_mean$minimum, col="blue")
abline(v=a_hat_median$minimum, col="green")
lines(a_hat_huber~delta, col="red")
legend(x="topleft", cex = 1, legend=c("Hyperbolic Estimates", "Huber Estimates", "Mean Estimate", "Median Estimate"), fill = c("black", "red", "blue", "green"))
library(boot)
data(bigcity)
y = bigcity$x
library(boot)
data(bigcity)
y = bigcity$x
delta = seq(0.001,max(y)-min(y),length.out=10000)
caliper = delta
hyperbolic_estimates = V_hyperbolic_from_risk_minimization(x=y,delta=delta)
#plot(hyperbolic_estimates~delta, xlab = "Estimate", xlim=c(0,0.3), ylim=c(0.194,0.22), ylab= "Delta/Caliper")
plot(hyperbolic_estimates~delta, xlab = "Estimate", ylab= "Delta/Caliper")
a_hat_mean = optimize(mean_squared_error_loss,interval,y=y,tol=.Machine$double.eps^0.5)
print(c(est=a_hat_mean$minimum, mean=mean(y)))
a_hat_median = optimize(mean_absolute_error_loss,interval,y=y,tol=.Machine$double.eps^0.5)
print(c(est=a_hat_median$minimum, median=median(y)))
# abline(v=a_hat_mean$minimum, col="blue")
# abline(v=a_hat_median$minimum, col="green")
M = 10000
caliper = seq(0.001,max(y)-min(y),length.out=10000)
a_hat_huber = rep(NA,M)
for(i in 1:M){
a_hat_huber[i] = optimize(mean_huber_loss,interval,y=y,caliper=caliper[i],tol=.Machine$double.eps^0.5)$minimum
}
# lines(a_hat_huber~delta, col="red")
legend(x="topleft", cex = 1, legend=c("Hyperbolic Estimates", "Huber Estimates", "Mean Estimate", "Median Estimate"), fill = c("black", "red", "blue", "green"))
library(boot)
data(bigcity)
y = bigcity$x
delta = seq(0.001,max(y)-min(y),length.out=10000)
caliper = delta
hyperbolic_estimates = V_hyperbolic_from_risk_minimization(x=y,delta=delta)
#plot(hyperbolic_estimates~delta, xlab = "Estimate", xlim=c(0,0.3), ylim=c(0.194,0.22), ylab= "Delta/Caliper")
plot(hyperbolic_estimates~delta, xlab = "Estimate", ylab= "Delta/Caliper")
a_hat_mean = optimize(mean_squared_error_loss,interval,y=y,tol=.Machine$double.eps^0.5)
print(c(est=a_hat_mean$minimum, mean=mean(y)))
a_hat_median = optimize(mean_absolute_error_loss,interval,y=y,tol=.Machine$double.eps^0.5)
print(c(est=a_hat_median$minimum, median=median(y)))
# abline(v=a_hat_mean$minimum, col="blue")
# abline(v=a_hat_median$minimum, col="green")
M = 10000
caliper = seq(0.001,max(y)-min(y),length.out=10000)
a_hat_huber = rep(NA,M)
for(i in 1:M){
a_hat_huber[i] = optimize(mean_huber_loss,interval,y=y,caliper=caliper[i],tol=.Machine$double.eps^0.5)$minimum
}
lines(a_hat_huber~delta, col="red")
legend(x="topleft", cex = 1, legend=c("Hyperbolic Estimates", "Huber Estimates", "Mean Estimate", "Median Estimate"), fill = c("black", "red", "blue", "green"))
knitr::opts_chunk$set(echo = TRUE)
f = function(a){
a^2-2*a+1
}
optimize(f,c(-10,10),tol=.Machine$double.eps^0.5)
g = function(a){
(a-2)^2*(a+2)^2
}
optimize(g,c(-10,0),tol=.Machine$double.eps^0.5)
optimize(g,c(0,10),tol=.Machine$double.eps^0.5)
optimize(g,c(-10,10),tol=.Machine$double.eps^0.5)
h = function(a,phi,theta){
(phi+theta/(1+theta)-a)^2
}
phi = 5
theta = -6
optimize(h,c(-100,100),phi=phi,theta=theta,tol=.Machine$double.eps^0.5)
opt_h_out = optimize(h,c(-100,100),phi=phi,theta=theta,tol=.Machine$double.eps^0.5)
print(opt_h_out)
print(opt_h_out$minimum)
print(opt_h_out$objective)
mean_squared_error_loss = function(a,y){
out = mean((y-a)^2)
return(out)
}
mean_absolute_error_loss = function(a,y){
out = mean(abs(y-a))
return(out)
}
data(rock)
y = rock$shape
plot(density(y,from=0),main="Density Estimate from Rock Sample")
lower = min(y)
upper = max(y)
interval = c(lower,upper)
a_hat_mean = optimize(mean_squared_error_loss,interval,y=y,tol=.Machine$double.eps^0.5)
print(c(est=a_hat_mean$minimum, mean=mean(y)))
a_hat_median = optimize(mean_absolute_error_loss,interval,y=y,tol=.Machine$double.eps^0.5)
print(c(est=a_hat_median$minimum, median=median(y)))
mean_huber_loss = function(a,y,caliper){
# first, a check to make sure the caliper is >0
if(caliper==0){caliper=1}else if(caliper<0){caliper= -caliper}
# we use ifelse to do logical comparisons on a vector
huber_loss = ifelse(abs(y-a)<=caliper,(y-a)^2/2,caliper*abs(y-a)-caliper^2/2)
out = mean(huber_loss)
return(out)
}
caliper = 0.1
a_hat_huber = optimize(mean_huber_loss,interval,y=y,caliper=caliper,tol=.Machine$double.eps^0.5)
a_hat_huber$minimum
caliper = 0.2
a_hat_huber = optimize(mean_huber_loss,interval,y=y,caliper=caliper,tol=.Machine$double.eps^0.5)
a_hat_huber$minimum
caliper = 0.05
a_hat_huber = optimize(mean_huber_loss,interval,y=y,caliper=caliper,tol=.Machine$double.eps^0.5)
a_hat_huber$minimum
M = 10000
caliper = seq(0.001,max(y)-min(y),length.out=M)
a_hat_huber = rep(NA,M)
for(i in 1:M){
a_hat_huber[i] = optimize(mean_huber_loss,interval,y=y,caliper=caliper[i],tol=.Machine$double.eps^0.5)$minimum
}
plot(a_hat_huber~caliper,type="l",xlab="Caliper",ylab="Estimate",main="Estimates from Huber Risk")
hyperbolic_loss = function(a,y,delta){
return(mean(sqrt(delta^2 + (y-a)^2) - delta))
# We take the mean because y is a vector and computing the value requires the average of the hyperbolic loss for the entire vector y
}
y <- rock$shape
delta <- 0.5
# the arguments a and delta are scalar while y is a vector
optimize(hyperbolic_loss, interval=range(y), y=y, delta=delta, tol=.Machine$double.eps^0.5)
hyperbolic_from_risk_minimization = function(x, ind=c(1:length(x)), delta) {
x = x[ind]
g = function(theta) {
return(mean(hyperbolic_loss(theta,x,delta)))
}
optimize_out = optimize(f=g,interval=range(x))
return(optimize_out$minimum)
}
V_hyperbolic_from_risk_minimization = Vectorize(hyperbolic_from_risk_minimization, vectorize.args = "delta")
delta = seq(0.001,max(y)-min(y),length.out=10000)
caliper = delta
hyperbolic_estimates = V_hyperbolic_from_risk_minimization(x=y,delta=delta)
plot(hyperbolic_estimates~delta, xlim=c(0,0.3), ylim=c(0.194,0.22), xlab = "Estimate", ylab= "Delta/Caliper")
abline(v=a_hat_mean$minimum, col="blue")
abline(v=a_hat_median$minimum, col="green")
lines(a_hat_huber~delta, col="red")
legend(x="topleft", cex = 1, legend=c("Hyperbolic Estimates", "Huber Estimates", "Mean Estimate", "Median Estimate"), fill = c("black", "red", "blue", "green"))
library(boot)
data(bigcity)
y = bigcity$x
delta = seq(0.001,max(y)-min(y),length.out=10000)
caliper = delta
hyperbolic_estimates = V_hyperbolic_from_risk_minimization(x=y,delta=delta)
#plot(hyperbolic_estimates~delta, xlab = "Estimate", xlim=c(0,0.3), ylim=c(0.194,0.22), ylab= "Delta/Caliper")
plot(hyperbolic_estimates~delta, xlab = "Estimate", ylab= "Delta/Caliper")
a_hat_mean = optimize(mean_squared_error_loss,interval,y=y,tol=.Machine$double.eps^0.5)
print(c(est=a_hat_mean$minimum, mean=mean(y)))
a_hat_median = optimize(mean_absolute_error_loss,interval,y=y,tol=.Machine$double.eps^0.5)
print(c(est=a_hat_median$minimum, median=median(y)))
# abline(v=a_hat_mean$minimum, col="blue")
# abline(v=a_hat_median$minimum, col="green")
M = 10000
caliper = seq(0.001,max(y)-min(y),length.out=10000)
a_hat_huber = rep(NA,M)
for(i in 1:M){
a_hat_huber[i] = optimize(mean_huber_loss,interval,y=y,caliper=caliper[i],tol=.Machine$double.eps^0.5)$minimum
}
lines(a_hat_huber~delta, col="red")
legend(x="topleft", cex = 1, legend=c("Hyperbolic Estimates", "Huber Estimates", "Mean Estimate", "Median Estimate"), fill = c("black", "red", "blue", "green"))
library(boot)
data(bigcity)
y = bigcity$x
delta = seq(0.001,max(y)-min(y),length.out=10000)
caliper = delta
hyperbolic_estimates = V_hyperbolic_from_risk_minimization(x=y,delta=delta)
plot(hyperbolic_estimates~delta, xlab = "Estimate", xlim=c(0,150), ylim=c(70,120), ylab= "Delta/Caliper")
a_hat_mean = optimize(mean_squared_error_loss,interval,y=y,tol=.Machine$double.eps^0.5)
print(c(est=a_hat_mean$minimum, mean=mean(y)))
a_hat_median = optimize(mean_absolute_error_loss,interval,y=y,tol=.Machine$double.eps^0.5)
print(c(est=a_hat_median$minimum, median=median(y)))
# abline(v=a_hat_mean$minimum, col="blue")
# abline(v=a_hat_median$minimum, col="green")
M = 10000
caliper = seq(0.001,max(y)-min(y),length.out=10000)
a_hat_huber = rep(NA,M)
for(i in 1:M){
a_hat_huber[i] = optimize(mean_huber_loss,interval,y=y,caliper=caliper[i],tol=.Machine$double.eps^0.5)$minimum
}
lines(a_hat_huber~delta, col="red")
legend(x="topleft", cex = 1, legend=c("Hyperbolic Estimates", "Huber Estimates", "Mean Estimate", "Median Estimate"), fill = c("black", "red", "blue", "green"))
library(boot)
data(bigcity)
y = bigcity$x
lower = min(y)
upper = max(y)
interval = c(lower,upper)
a_hat_mean = optimize(mean_squared_error_loss,interval,y=y,tol=.Machine$double.eps^0.5)
print(c(est=a_hat_mean$minimum, mean=mean(y)))
a_hat_median = optimize(mean_absolute_error_loss,interval,y=y,tol=.Machine$double.eps^0.5)
print(c(est=a_hat_median$minimum, median=median(y)))
library(boot)
data(bigcity)
y = bigcity$x
lower = min(y)
upper = max(y)
interval = c(lower,upper)
a_hat_mean = optimize(mean_squared_error_loss,interval,y=y,tol=.Machine$double.eps^0.5)
print(c(est=a_hat_mean$minimum, mean=mean(y)))
a_hat_median = optimize(mean_absolute_error_loss,interval,y=y,tol=.Machine$double.eps^0.5)
print(c(est=a_hat_median$minimum, median=median(y)))
M = 10000
caliper = seq(0.001,max(y)-min(y),length.out=10000)
a_hat_huber = rep(NA,M)
for(i in 1:M){
a_hat_huber[i] = optimize(mean_huber_loss,interval,y=y,caliper=caliper[i],tol=.Machine$double.eps^0.5)$minimum
}
library(boot)
data(bigcity)
y = bigcity$x
lower = min(y)
upper = max(y)
interval = c(lower,upper)
a_hat_mean = optimize(mean_squared_error_loss,interval,y=y,tol=.Machine$double.eps^0.5)
print(c(est=a_hat_mean$minimum, mean=mean(y)))
a_hat_median = optimize(mean_absolute_error_loss,interval,y=y,tol=.Machine$double.eps^0.5)
print(c(est=a_hat_median$minimum, median=median(y)))
M = 10000
caliper = seq(0.001,max(y)-min(y),length.out=10000)
a_hat_huber = rep(NA,M)
for(i in 1:M){
a_hat_huber[i] = optimize(mean_huber_loss,interval,y=y,caliper=caliper[i],tol=.Machine$double.eps^0.5)$minimum
}
V_hyperbolic_from_risk_minimization = Vectorize(hyperbolic_from_risk_minimization, vectorize.args = "delta")
delta = seq(0.001,max(y)-min(y),length.out=10000)
caliper = delta
hyperbolic_estimates = V_hyperbolic_from_risk_minimization(x=y,delta=delta)
# plot(hyperbolic_estimates~delta, xlim=c(0,0.3), ylim=c(0.194,0.22), xlab = "Estimate", ylab= "Delta/Caliper")
plot(hyperbolic_estimates~delta, xlab = "Estimate", ylab= "Delta/Caliper")
abline(v=a_hat_mean$minimum, col="blue")
abline(v=a_hat_median$minimum, col="green")
lines(a_hat_huber~delta, col="red")
legend(x="topleft", cex = 1, legend=c("Hyperbolic Estimates", "Huber Estimates", "Mean Estimate", "Median Estimate"), fill = c("black", "red", "blue", "green"))
knitr::opts_chunk$set(echo = TRUE)
cities<-read.table("top200cities.txt", header = TRUE)
cities<-read.table("/top200cities.txt", header = TRUE)
cities<-read.table("top200cities.txt", header = TRUE)
cities<-read.table("top200cities.txt", header = TRUE)
cities
cities<-read.table("top200cities.txt", header = TRUE)
names(cities)
midpoint<-98.35
numOfWest<-cities[cities$longitude>midpoint]
midpoint<-98.35
numOfWest<-cities[cities$longitude>midpoint,]
numOfEast<-cities[cities$longitude>midpoint,]
numOfWest
midpoint<-98.35
numOfWest<-nrow(cities[cities$longitude>midpoint,])
numOfEast<-nrow(cities[cities$longitude>midpoint,])
midpoint<-98.35
numOfWest<-nrow(cities[cities$longitude>midpoint,])
numOfEast<-nrow(cities[cities$longitude>midpoint,])
numOfWest
numOfEast
midpoint<-98.35
numOfWest<-nrow(cities[cities$longitude>midpoint,])
numOfEast<-nrow(cities[cities$longitude<midpoint,])
numOfWest
numOfEast
1.	 Install R on your machine by visiting https://www.r-project.org\ \
midpointLong<-98.35
numOfWest<-nrow(cities[cities$longitude>midpointLong,])
numOfEast<-nrow(cities[cities$longitude<midpointLong,])
numOfWest
numOfEast
midpointLat<-39.5
numOfNorth<-nrow(cities[cities$latitude>midpointLat,])
numOfSouth<-nrow(cities[cities$latitude>midpointLat,])
numOfNorth
numOfSouth
midpointLat<-39.5
numOfNorth<-nrow(cities[cities$latitude>midpointLat,])
numOfSouth<-nrow(cities[cities$latitude<midpointLat,])
numOfNorth
numOfSouth
cities$popdensitysqmi[cities$city=="Miami"]
cities$city[cities$pctchange>50]
mostcities<-cities[cities$pctchange<30]
mostcities<-cities[cities$pctchange<30,]
mostcities
mostcities<-mostcities[cities$longitude>140,]
mostcities
mostcities<-cities[cities$pctchange<30,]
mostcities
mostcities<-mostcities[cities$longitude<140,]
mostcities
mostcities<-cities[cities$pctchange<30,]
mostcities
mostcities<-mostcities[mostcities$longitude<140,]
mostcities
mostcities<-cities[cities$pctchange<30,]
mostcities<-mostcities[mostcities$longitude<140,]
mostcities<-cities[cities$pctchange<30,]
mostcities<-mostcities[mostcities$longitude<140,]
plot(mostcities)
install.packages("ggplot")
install.packages("ggplot")
setwd("~/OneDrive - Indiana University/cogs-q370/Final Project/My Analysis")
knitr::opts_chunk$set(echo = TRUE)
library(ez)
library(dplyr)
library(ggplot2)
data<-read.table("cleanedData.csv", sep=',', header = TRUE)
head(data)
table1 <- tapply(X=data$enjoyment,INDEX=list(data$artist,data$attributed),FUN=mean) #apply mean function to words recalled broken down by motivation and type of stimulus
table1 <- tapply(X=data$enjoyment,INDEX=list(data$artist,data$attributed),FUN=mean) #apply mean function to words recalled broken down by motivation and type of stimulus
table1 <- tapply(X=data$enjoyment,INDEX=list(data$artist,data$attributed),FUN=mean) #apply mean function to words recalled broken down by motivation and type of stimulus
knitr::opts_chunk$set(echo = TRUE)
library(ez) #for doing the ANOVAs
library(dplyr)
library(ggplot2)
data<-read.table("dalle.txt", sep=' ', header = TRUE) # I separated the columns by tabs, hence the " " for sep
table1 <- tapply(X=data$enjoyment,INDEX=list(data$artist,data$attributed),FUN=mean) #apply mean function to words recalled broken down by motivation and type of stimulus
table1 # show means so that one can begin to interpret the data
model<-ezANOVA(data=data,dv=enjoyment,within=c(artist,attributed),wid=subject) # conduct a repeated measures ANOVA - dv = dependent variable.  within = a list of all of the within subject variables.  wid = variable that is used to group data by subject
model # show results of the ANOVA model
ggplot(data,aes(x=artist,y=enjoyment,fill=attributed))+stat_summary(fun=mean,geom="bar",position=position_dodge(width=0.9))+stat_summary(fun.data=mean_cl_normal,geom="errorbar",position=position_dodge(0.9))+ xlab("Artist") + ylab("Enjoyment")
table1 <- tapply(X=data$enjoyment,INDEX=list(data$Artist,data$Attributed),FUN=mean) #apply mean function to words recalled broken down by motivation and type of stimulus
knitr::opts_chunk$set(echo = TRUE)
library(ez)
library(dplyr)
library(ggplot2)
data<-read.table("cleanedData.csv", sep=',', header = TRUE)
head(data)
table1 <- tapply(X=data$Enjoyment,INDEX=list(data$Artist,data$Attributed),FUN=mean) #apply mean function to words recalled broken down by motivation and type of stimulus
table1 # show means so that one can begin to interpret the data
model<-ezANOVA(data=data,dv=Enjoyment,within=c(Artist,Attributed),wid=subject) # conduct a repeated measures ANOVA - dv = dependent variable.  within = a list of all of the within subject variables.  wid = variable that is used to group data by subject
knitr::opts_chunk$set(echo = TRUE)
library(ez)
library(dplyr)
library(ggplot2)
data<-read.table("cleanedData.csv", sep=',', header = TRUE)
head(data)
table1 <- tapply(X=data$Enjoyment,INDEX=list(data$Artist,data$Attributed),FUN=mean) #apply mean function to words recalled broken down by motivation and type of stimulus
table1 # show means so that one can begin to interpret the data
model<-ezANOVA(data=data,dv=Enjoyment,within=c(Artist,Attributed),wid=Subject) # conduct a repeated measures ANOVA - dv = dependent variable.  within = a list of all of the within Subject variables.  wid = variable that is used to group data by Subject
model # show results of the ANOVA model
ggplot(data,aes(x=Artist,y=Enjoyment,fill=Attributed))+stat_summary(fun=mean,geom="bar",position=position_dodge(width=0.9))+stat_summary(fun.data=mean_cl_normal,geom="errorbar",position=position_dodge(0.9))+ xlab("Artist") + ylab("Enjoyment")
